{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQZFjbPw8x5C",
        "outputId": "12a8222f-73d3-485a-c02c-a71ae7d4c087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1O3m1GXyS4OpHk5gkBSCJauRPTcw8y-n_\n",
            "From (redirected): https://drive.google.com/uc?id=1O3m1GXyS4OpHk5gkBSCJauRPTcw8y-n_&confirm=t&uuid=d2dc27a7-b18b-4562-ae20-95da44e7a0ae\n",
            "To: /content/Celeb-df-V2-faces-extracted.zip\n",
            "100% 260M/260M [00:06<00:00, 39.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Dataset\n",
        "!gdown \n",
        "!unzip -q Celeb-df-V2-faces-extracted.zip\n",
        "\n",
        "# Model\n",
        "!gdown "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9pCVn5Mh-P48"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BqHnGbaE-R1p"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('/content/cnn_fully.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NHkhuF_5_e6-"
      },
      "outputs": [],
      "source": [
        "def read_video(video_path):\n",
        "    video_frames = []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    while True:\n",
        "        ret, current_frame = cap.read()\n",
        "        if not ret: break\n",
        "        current_frame = cv2.resize(current_frame, (299, 299))\n",
        "        current_frame = cv2.cvtColor(current_frame, cv2.COLOR_BGR2RGB)\n",
        "        video_frames.append(current_frame)\n",
        "    cap.release()\n",
        "\n",
        "    video_frames = np.array([video_frames]) / 255.\n",
        "\n",
        "    return video_frames\n",
        "\n",
        "\n",
        "real_videos = os.listdir(\"/content/Celeb-df-V2-faces-extracted/test/real\")\n",
        "fake_videos = os.listdir(\"/content/Celeb-df-V2-faces-extracted/test/fake\")\n",
        "\n",
        "real_videos_path = [(os.path.join(\"/content/Celeb-df-V2-faces-extracted/test/real\", video_path), np.array([1., 0.])) for video_path in real_videos]\n",
        "fake_videos_path = [(os.path.join(\"/content/Celeb-df-V2-faces-extracted/test/fake\", video_path), np.array([0., 1.])) for video_path in fake_videos]\n",
        "\n",
        "dataset = real_videos_path + fake_videos_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrXYcMHyCOKI",
        "outputId": "573a846b-c2f5-4101-d56b-30ca0705c77c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49\n",
            "99\n",
            "149\n",
            "199\n",
            "249\n",
            "299\n",
            "349\n",
            "399\n",
            "449\n",
            "499\n",
            "Total videos: 518\n",
            "Correct Videos: 504\n",
            "Wrong videos: 14\n"
          ]
        }
      ],
      "source": [
        "wrong_videos_path = []\n",
        "\n",
        "for i, (video_path, label) in enumerate(dataset):\n",
        "    video = read_video(video_path)\n",
        "    prediction = model.predict(video, verbose = 0)\n",
        "\n",
        "    if np.argmax(prediction) != np.argmax(label):\n",
        "        wrong_videos_path.append(video_path)\n",
        "\n",
        "    if (i+1) % 50 == 0:\n",
        "        print(f\"{i+1}\", end = \" | \")\n",
        "\n",
        "total_videos = len(dataset)\n",
        "wrong = len(wrong_videos_path)\n",
        "right = total_videos - wrong\n",
        "\n",
        "print(\"Total videos:\", total_videos)\n",
        "print(\"Correct Videos:\", right)\n",
        "print(\"Wrong videos:\", wrong)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ua281eJFklG",
        "outputId": "d618dc81-f37d-42b9-b05a-b8cba04e74c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: wrong_classification/ (stored 0%)\n",
            "  adding: wrong_classification/real/ (stored 0%)\n",
            "  adding: wrong_classification/real/id32_0006_segment_1.mp4 (deflated 29%)\n",
            "  adding: wrong_classification/real/id31_0007_segment_1.mp4 (deflated 3%)\n",
            "  adding: wrong_classification/real/id21_0009_segment_1.mp4 (deflated 5%)\n",
            "  adding: wrong_classification/real/00279_segment_1.mp4 (deflated 19%)\n",
            "  adding: wrong_classification/real/id35_0003_segment_1.mp4 (deflated 3%)\n",
            "  adding: wrong_classification/real/id6_0005_segment_1.mp4 (deflated 8%)\n",
            "  adding: wrong_classification/real/id53_0003_segment_1.mp4 (deflated 4%)\n",
            "  adding: wrong_classification/fake/ (stored 0%)\n",
            "  adding: wrong_classification/fake/id29_id30_0009_segment_1.mp4 (deflated 10%)\n",
            "  adding: wrong_classification/fake/id35_id16_0007_segment_1.mp4 (deflated 16%)\n",
            "  adding: wrong_classification/fake/id10_id12_0004_segment_1.mp4 (deflated 10%)\n",
            "  adding: wrong_classification/fake/id17_id1_0000_segment_1.mp4 (deflated 7%)\n",
            "  adding: wrong_classification/fake/id0_id1_0005_segment_1.mp4 (deflated 3%)\n",
            "  adding: wrong_classification/fake/id4_id0_0004_segment_1.mp4 (deflated 8%)\n",
            "  adding: wrong_classification/fake/id50_id56_0005_segment_1.mp4 (deflated 11%)\n"
          ]
        }
      ],
      "source": [
        "dirpath = \"wrong_classification\"\n",
        "if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
        "    shutil.rmtree(dirpath)\n",
        "\n",
        "os.makedirs(dirpath + \"/real\")\n",
        "os.makedirs(dirpath + \"/fake\")\n",
        "\n",
        "for path in wrong_videos_path:\n",
        "    if \"real\" in path:\n",
        "        shutil.copy(src = path, dst = \"wrong_classification/real\")\n",
        "    else:\n",
        "        shutil.copy(src = path, dst = \"wrong_classification/fake\")\n",
        "\n",
        "!zip -r wrong_classification.zip wrong_classification"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
